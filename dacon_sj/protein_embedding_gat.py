# -*- coding: utf-8 -*-
"""gat_protein_gpu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xs5KVn5Co0AhlcgBXHgY7YnRYHqmLeks

# Import
"""

import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

#pip install torch_geometric

#pip install rdkit

import torch
import torch.nn as nn
import torch.optim as optim
import torch_geometric.nn as pyg_nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
import rdkit
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit.Chem import rdmolops
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GATConv, global_mean_pool
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error

"""# Data"""

protein_df = pd.read_csv('/home/aix23606/sojeong/new_drug_ai/data/uniprot_sequence_bert_embedding.tsv', sep='\t')
protein_df

protein_df['sequence_length'] = protein_df['sequence'].apply(len)
max_length_df = protein_df.loc[protein_df.groupby('uniprot_id')['sequence_length'].idxmax()]
max_length_df = max_length_df.drop(columns=['sequence_length'])
protein_df = max_length_df

smiles_df = pd.read_csv('/home/aix23606/sojeong/new_drug_ai/data/BindingDB_IC50.csv')

smiles_df = smiles_df[['Smiles', 'Uniprot', 'pIC50']]
smiles_df = smiles_df.drop_duplicates(subset=['Smiles', 'Uniprot'])
smiles_df.replace([np.inf, -np.inf], np.nan, inplace=True)
smiles_df = smiles_df.dropna(subset=['pIC50'])
smiles_df.rename(columns={'Uniprot': 'uniprot_id'}, inplace=True)

merged_df = smiles_df.merge(protein_df, on='uniprot_id', how='inner')

protein_embeddings = merged_df.iloc[:, 4:].values
protein_embeddings = (protein_embeddings - np.mean(protein_embeddings, axis=0)) / np.std(protein_embeddings, axis=0)
protein_embeddings.shape

smiles_df = merged_df[['Smiles', 'pIC50']]

"""# Fuctions

## smiles2graph
"""

my_elements = {
    1: "H", 2: "He", 3: "Li", 4: "Be", 5: "B", 6: "C", 7: "N", 8: "O", 9: "F", 10: "Ne",
    11: "Na", 12: "Mg", 13: "Al", 14: "Si", 15: "P", 16: "S", 17: "Cl", 18: "Ar", 19: "K", 20: "Ca",
    21: "Sc", 22: "Ti", 23: "V", 24: "Cr", 25: "Mn", 26: "Fe", 27: "Co", 28: "Ni", 29: "Cu", 30: "Zn",
    31: "Ga", 32: "Ge", 33: "As", 34: "Se", 35: "Br", 36: "Kr", 37: "Rb", 38: "Sr", 39: "Y", 40: "Zr",
    41: "Nb", 42: "Mo", 43: "Tc", 44: "Ru", 45: "Rh", 46: "Pd", 47: "Ag", 48: "Cd", 49: "In", 50: "Sn",
    51: "Sb", 52: "Te", 53: "I", 54: "Xe", 55: "Cs", 56: "Ba", 57: "La", 58: "Ce", 59: "Pr", 60: "Nd",
    61: "Pm", 62: "Sm", 63: "Eu", 64: "Gd", 65: "Tb", 66: "Dy", 67: "Ho", 68: "Er", 69: "Tm", 70: "Yb",
    71: "Lu", 72: "Hf", 73: "Ta", 74: "W", 75: "Re", 76: "Os", 77: "Ir", 78: "Pt", 79: "Au", 80: "Hg",
    81: "Tl", 82: "Pb", 83: "Bi", 84: "Po", 85: "At", 86: "Rn", 87: "Fr", 88: "Ra", 89: "Ac", 90: "Th",
    91: "Pa", 92: "U", 93: "Np", 94: "Pu", 95: "Am", 96: "Cm", 97: "Bk", 98: "Cf", 99: "Es", 100: "Fm",
    101: "Md", 102: "No", 103: "Lr", 104: "Rf", 105: "Db", 106: "Sg", 107: "Bh", 108: "Hs", 109: "Mt", 110: "Ds",
    111: "Rg", 112: "Cn", 113: "Nh", 114: "Fl", 115: "Mc", 116: "Lv", 117: "Ts", 118: "Og"
}

def smiles2graph(sml):
    """Argument for the RD2NX function should be a valid SMILES sequence
    returns: the graph
    """
    try:
        m = rdkit.Chem.MolFromSmiles(sml)

        if m is None:
                print(f"Invalid SMILES: {sml}")
                return None

        m = rdkit.Chem.AddHs(m)
        order_string = {
            rdkit.Chem.rdchem.BondType.SINGLE: 1,
            rdkit.Chem.rdchem.BondType.DOUBLE: 2,
            rdkit.Chem.rdchem.BondType.TRIPLE: 3,
            rdkit.Chem.rdchem.BondType.AROMATIC: 4,
        }
        N = len(list(m.GetAtoms()))
        nodes = np.zeros((N, len(my_elements)))
        lookup = list(my_elements.keys())
        for i in m.GetAtoms():
            nodes[i.GetIdx(), lookup.index(i.GetAtomicNum())] = 1

        adj = np.zeros((N, N, 5))
        for j in m.GetBonds():
            u = min(j.GetBeginAtomIdx(), j.GetEndAtomIdx())
            v = max(j.GetBeginAtomIdx(), j.GetEndAtomIdx())
            order = j.GetBondType()
            if order in order_string:
                order = order_string[order]
            else:
                raise Warning("Ignoring bond order" + order)
            adj[u, v, order] = 1
            adj[v, u, order] = 1
        return nodes, adj

    except Exception as e:
        print(f"Error processing SMILES {sml}: {e}")
        return None

def prepare_data(smiles_list, protein_embeddings, pIC50_values):
    graph_data = []
    for idx, sml in enumerate(smiles_list):
        result = smiles2graph(sml)
        if result is None:
            print(f"Skipping invalid SMILES at index {idx}")
            continue

        nodes, adj = result
        protein_embedding = torch.tensor(protein_embeddings[idx], dtype=torch.float32)
        target = torch.tensor([pIC50_values[idx]], dtype=torch.float32)

        edge_index = torch.tensor(np.nonzero(np.sum(adj, axis=2)), dtype=torch.long)

        data = Data(x=torch.tensor(nodes, dtype=torch.float32), edge_index=edge_index, y=target)
        data.protein_embedding = protein_embedding

        graph_data.append(data)

    return graph_data

"""## GAT model"""

class GATModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, heads=8):
        super(GATModel, self).__init__()
        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)
        self.gat2 = GATConv(hidden_dim * heads, hidden_dim, heads=heads, concat=False)
        self.fc = nn.Linear(hidden_dim, output_dim)

        combined_vector_dim = output_dim + 1024
        self.fc_out = nn.Linear(combined_vector_dim, 1)

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch

        x = self.gat1(x, edge_index)
        x = F.relu(x)
        x = self.gat2(x, edge_index)
        x = F.relu(x)

        x = global_mean_pool(x, batch)

        protein_embedding = data.protein_embedding  # (flattened) size: [32768]

        batch_size = x.size(0)

        # protein_embedding이 flatten되어 있다면 다시 (batch_size, 1024)
        if protein_embedding.size(0) == batch_size * 1024:
            protein_embedding = protein_embedding.view(x.size(0), -1)

        combined_vector = torch.cat([x, protein_embedding], dim=1)

        out = self.fc_out(combined_vector)
        return out

"""# Implement"""

pIC50_values = smiles_df['pIC50'].values
dataset = prepare_data(smiles_df['Smiles'], protein_embeddings, pIC50_values)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

protein_embeddings.shape

smiles_df['Smiles'].shape

gat_model = GATModel(input_dim=len(my_elements), hidden_dim=1024, output_dim=1024)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.001)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
gat_model = gat_model.to(device)

print(gat_model)

for epoch in range(100):
    total_loss = 0
    for data in train_loader:
        optimizer.zero_grad()

        output = gat_model(data)

        target = data.y

        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f'Epoch {epoch + 1}, Loss: {total_loss:.4f}')

"""# Test & Submission

## Functions
"""

def pIC50_to_IC50(pic50_values):
    return 10 ** (9 - pic50_values)

def IC50_to_pIC50(ic50_values):
    return 9 - np.log10(ic50_values)

"""## Test: k-means test data"""

test_df = pd.read_csv('/home/aix23606/sojeong/new_drug_ai/data/selected_test_km.csv')

submit_protein_embed = protein_df[(protein_df['uniprot_id'] == 'Q9NWZ3')]
submit_protein_113 = pd.concat([submit_protein_embed]*113, ignore_index=True)
submit_protein = submit_protein_113.iloc[:, 2:].values

pIC50_values = test_df['pIC50'].values
test_dataset = prepare_data(test_df['Smiles'], submit_protein, pIC50_values)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)

gat_model.eval()

with torch.no_grad():
    total_loss = 0
    for data in test_loader:
        output = gat_model(data)
        loss = criterion(output, data.y)
        total_loss += loss.item()

    avg_loss = total_loss / len(test_loader)
    print(f'Test Loss: {avg_loss}')

predictions = []
actuals = []
with torch.no_grad():
    for data in test_loader:
        output = gat_model(data)
        predictions.append(output.cpu().numpy())
        actuals.append(data.y.cpu().numpy())

actuals = np.concatenate([np.array(data.y.cpu().numpy()) for data in test_loader], axis=0)
predictions = np.concatenate([np.array(gat_model(data).cpu().detach().numpy()) for data in test_loader], axis=0)

# pIC50을 IC50으로 변환하여 성능 평가
actuals_ic50 = pIC50_to_IC50(np.array(actuals))
predictions_ic50 = pIC50_to_IC50(np.array(predictions))

rmse = np.sqrt(mean_squared_error(actuals_ic50, predictions_ic50))
normalized_rmse = rmse / (np.max(actuals_ic50) - np.min(actuals_ic50))

# IC50을 pIC50으로 변환하여 성능 평가
actuals_ic50 = IC50_to_pIC50(actuals_ic50)
predictions_ic50 = IC50_to_pIC50(predictions_ic50)

absolute_error = np.abs(actuals_ic50 - predictions_ic50)
correct_ratio = np.mean(absolute_error <= 0.5)

score = 0.5 * (1 - min(normalized_rmse, 1)) + 0.5 * correct_ratio

print(f"Normalized RMSE (A): {normalized_rmse}")
print(f"Correct Ratio (B): {correct_ratio}")
print(f"Score: {score}")

"""## Submit"""

submit_df = pd.read_csv('/home/aix23606/sojeong/new_drug_ai/data/test.csv')

def prepare_data_for_test(smiles_list, protein_embeddings):
    graph_data = []
    for idx, sml in enumerate(smiles_list):
        result = smiles2graph(sml)
        if result is None:
            print(f"Skipping invalid SMILES at index {idx}")
            continue

        nodes, adj = result
        protein_embedding = torch.tensor(protein_embeddings[idx], dtype=torch.float32)

        edge_index = torch.tensor(np.nonzero(np.sum(adj, axis=2)), dtype=torch.long)

        data = Data(x=torch.tensor(nodes, dtype=torch.float32), edge_index=edge_index)
        data.protein_embedding = protein_embedding
        print(f"Data {idx}: x size: {data.x.size()}, edge_index size: {data.edge_index.size()}, protein_embedding size: {data.protein_embedding.size()}")

        graph_data.append(data)

    return graph_data

submit_dataset = prepare_data_for_test(submit_df['Smiles'], submit_protein)
submit_loader = DataLoader(submit_dataset, batch_size=32, shuffle=True)

gat_model.eval()

predictions = []

with torch.no_grad():
    for data in submit_loader:
        output = gat_model(data)
        predictions.append(output.cpu().numpy())

predictions = np.concatenate([np.array(gat_model(data).cpu().detach().numpy()) for data in submit_loader], axis=0)

submit = pd.read_csv('/home/aix23606/sojeong/new_drug_ai/data/sample_submission.csv')
submit['IC50_nM'] = pIC50_to_IC50(np.array(predictions))
submit.head()

submit.to_csv('/home/aix23606/sojeong/new_drug_ai/submit_gat_gpu_0906.csv', index=False)